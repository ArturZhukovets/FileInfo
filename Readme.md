Counter(sentence_count=1326602, chars_count=0, num_of_words_count=24261251, max_letters_count=0, spec_symbols_count=0)

[0.9688031509995199, 0.7979195570005686, 0.7556850830005715] -> using dictionary
[0.8613121320013306, 0.7978110540007037, 0.7593010590007907] -> using getattr
[0.9573215170003095, 0.9261823729993921, 0.9478666860013618] -> evaluating all parameters deafult
[1.16142743599994, 1.1334737459983444, 1.1363684839998314] -> evaluating all parameters with dictionary map
[0.9869364340011089, 0.9858787419998407, 0.9975373699999182] -> evaluating all parameters with dictonary imap
[0.9943560199990316, 1.0059616489998007, 1.0193950519987993] -> evaluating all parameters with dictionary imap_unordered



Сейчас я буду в виде прогрес бара использовать сколько уже запроцешено чанков. Но я не имею финальной точки (из-за генератора)
[5.566737364999426, 5.685719033001078, 5.734974144001171] - Result

Второе решение использовать как финальную точку количество чанков (которое равно COUNT_LINES / CHUNK_SIZE)
[5.768858715000533, 6.353475332001835, 5.977082828998391] - Result (with final value)

Как видно результат лишь немного хуже. Всё дело в том, что как оказлось count_lines можно быстро посчитать,
используя subprocess wc -l <path_to_file>


[18.233091122001497, 18.183018535000883, 18.1621691620021]
100%|██████████| 7960/7960 [00:05<00:00, 1519.79chunks/s]
100%|██████████| 7960/7960 [00:05<00:00, 1458.72chunks/s]
100%|██████████| 7960/7960 [00:05<00:00, 1441.07chunks/s]
[5.622209247001592, 5.858101257999806, 5.929863863999344]
[30.68182172700108, 30.503753517001314, 30.411564104000718]

# TODO посмотреть почему у 3го решения такая низкая производительность.
# TODO Оптимизировать лучшее решение




	*** COUNT LINES EVAL ***
[24.004367661000288, 24.159718017999694, 23.953583205999166] -> evaluating in one proccess
[5.6344042160017125, 5.865766553000867, 6.0084244110003056] -> evaluating in many proccess